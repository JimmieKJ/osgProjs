// ***DO NOT EDIT THIS FILE - IT IS AUTOMATICALLY GENERATED BY CMAKE***

#include <osgEarth/Shaders>

namespace osgEarth
{
    Shaders::Shaders()
    {
        // AlphaEffect
        AlphaEffectFragment = "AlphaEffect.frag.glsl";
        _sources[AlphaEffectFragment] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
\n
$__HASHTAG__pragma vp_entryPoint oe_alphaEffect_frag\n
$__HASHTAG__pragma vp_location   fragment_coloring\n
$__HASHTAG__pragma vp_order      0.5\n
\n
uniform float oe_alphaEffect_alpha;\n
\n
void oe_alphaEffect_frag(inout vec4 color)\n
{\n
    color = color * oe_alphaEffect_alpha;\n
}\n
\n
);


        // Depth Offset
        DepthOffsetVertex = "DepthOffset.vert.glsl";
       _sources[DepthOffsetVertex] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
$GLSL_DEFAULT_PRECISION_FLOAT\n
\n
$__HASHTAG__pragma vp_entryPoint oe_depthOffset_vertex\n
$__HASHTAG__pragma vp_location   vertex_view\n
$__HASHTAG__pragma vp_order      0.8\n
\n
uniform float oe_depthOffset_minBias;\n
uniform float oe_depthOffset_maxBias;\n
uniform float oe_depthOffset_minRange;\n
uniform float oe_depthOffset_maxRange;\n
\n
void oe_depthOffset_vertex(inout vec4 vertexView)\n
{\n
    // calculate range to target:\n
    float range = length(vertexView.xyz);\n
\n
    // calculate the depth offset bias for this range:\n
    float ratio = (clamp(range, oe_depthOffset_minRange, oe_depthOffset_maxRange)-oe_depthOffset_minRange)/(oe_depthOffset_maxRange-oe_depthOffset_minRange);\n
    float bias = oe_depthOffset_minBias + ratio * (oe_depthOffset_maxBias-oe_depthOffset_minBias);\n
\n
	// clamp the bias to 1/2 of the range of the vertex. We don't want to \n
    // pull the vertex TOO close to the camera and certainly not behind it.\n
    bias = min(bias, range*0.5);\n
\n
    //   pull the vertex towards the camera.\n
    vec3 pullVec = normalize(vertexView.xyz);\n
    vec3 simVert3 = vertexView.xyz - pullVec*bias;\n
    vertexView = vec4(simVert3, 1.0);\n
}\n
);


       // Draping
       DrapingVertex = "Draping.vert.glsl";
       _sources[DrapingVertex] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
$GLSL_DEFAULT_PRECISION_FLOAT\n
\n
$__HASHTAG__pragma vp_entryPoint oe_overlay_vertex\n
$__HASHTAG__pragma vp_location   vertex_view\n
\n
uniform mat4 oe_overlay_texmatrix;\n
uniform float oe_overlay_rttLimitZ;\n
\n
out vec4 oe_overlay_texcoord;\n
\n
void oe_overlay_vertex(inout vec4 vertexVIEW)\n
{\n
    oe_overlay_texcoord = oe_overlay_texmatrix * vertexVIEW;\n
}\n
);

       DrapingFragment = "Draping.frag.glsl";
       _sources[DrapingFragment] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
$GLSL_DEFAULT_PRECISION_FLOAT\n
\n
$__HASHTAG__pragma vp_entryPoint oe_overlay_fragment\n
$__HASHTAG__pragma vp_location   fragment_coloring\n
$__HASHTAG__pragma vp_order      0.6\n
\n
uniform bool oe_isPickCamera;\n
uniform sampler2D oe_overlay_tex;\n
in vec4 oe_overlay_texcoord;\n
\n
void oe_overlay_fragment(inout vec4 color)\n
{\n
    vec4 texel = texture2DProj(oe_overlay_tex, oe_overlay_texcoord);\n
    vec4 blendedTexel = vec4( mix( color.rgb, texel.rgb, texel.a ), color.a);\n
\n
    float pick = oe_isPickCamera? 1.0 : 0.0;\n
    color = mix(blendedTexel, texel, pick);\n
}\n
\n
);


        // GPU Clamping
        GPUClampingVertex = "GPUClamping.vert.glsl";
        _sources[GPUClampingVertex] = OE_MULTILINE($__HASHTAG__version 130\n
\n
$__HASHTAG__pragma vp_entryPoint oe_clamp_vertex\n
$__HASHTAG__pragma vp_location   vertex_view\n
$__HASHTAG__pragma vp_order      0.5\n
\n
$__HASHTAG__pragma include GPUClamping.vert.lib.glsl\n
\n
in vec4 oe_clamp_attrs;     // vertex attribute\n
in float oe_clamp_height;   // vertex attribute\n
\n
out float oe_clamp_alpha;\n
\n
uniform bool oe_clamp_hasAttrs;\n
uniform bool oe_isGeocentric;\n
uniform float oe_clamp_altitudeOffset;\n
uniform float oe_clamp_horizonDistance2;\n
\n
void oe_clamp_vertex(inout vec4 vertexView)\n
{\n
    const float ClampToAnchor = 1.0;\n
\n
    // check distance; alpha out if its beyone the horizon distance.\n
    oe_clamp_alpha = oe_isGeocentric ? \n
        clamp(oe_clamp_horizonDistance2 - (vertexView.z*vertexView.z), 0.0, 1.0) :\n
        1.0;\n
\n
    // if visible, calculate clamping.\n
    // note: no branch divergence in the vertex shader\n
    if ( oe_clamp_alpha > 0.0 )\n
    {\n
        bool relativeToAnchor = oe_clamp_hasAttrs && (oe_clamp_attrs.a == ClampToAnchor);\n
\n
        float verticalOffset = oe_clamp_hasAttrs ? oe_clamp_attrs.z : 0.0;\n
\n
        // if we are using the anchor point, xform it into view space to prepare\n
        // for clamping. Force Z=0 for anchoring.\n
        vec4 pointToClamp = relativeToAnchor?\n
            gl_ModelViewMatrix * vec4(oe_clamp_attrs.xy, 0.0, 1.0) :\n
            vertexView;\n
\n
        // find the clamped point.\n
        vec4  clampedPoint;\n
        float depth;\n
        oe_getClampedViewVertex(pointToClamp, clampedPoint, depth);\n
\n
        float dh = verticalOffset + oe_clamp_altitudeOffset;\n
\n
        if ( relativeToAnchor )\n
        {\n
            // if we are clamping relative to the anchor point, adjust the HAT based on the\n
            // distance from the anchor point to the terrain. Since distance() is unsigned,\n
            // we use the vector dot product to calculate whether to adjust up or down.\n
            float dist = distance(pointToClamp, clampedPoint);\n
            float dir  = sign(dot(clampedPoint-pointToClamp, vertexView-pointToClamp));\n
            dh += (dist * dir);\n
        }\n
        else\n
        {\n
            // if we are clamping to the terrain, the vertex becomes the\n
            // clamped point\n
            vertexView.xyz = clampedPoint.xyz;\n
            dh += oe_clamp_height;\n
        }\n
        \n
        // calculate the up vector along which clamping will occur (in either direction)\n
        vec3 up;\n
        oe_getClampingUpVector( up );\n
        vertexView.xyz += up*dh;\n
\n
        // if the clamped depth value is near the far plane, suppress drawing\n
        // to avoid rendering anomalies.\n
        oe_clamp_alpha = 1.0-step(0.9999, depth);\n
    }\n
}\n
\n
);

        GPUClampingFragment = "GPUClamping.frag.glsl";
        _sources[GPUClampingFragment] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
\n
$__HASHTAG__pragma vp_entryPoint oe_clamp_fragment\n
$__HASHTAG__pragma vp_location   fragment_coloring\n
\n
in float oe_clamp_alpha;\n
\n
void oe_clamp_fragment(inout vec4 color)\n
{\n
    // adjust the alpha component to "hide" geometry beyond the visible horizon.\n
    color.a *= oe_clamp_alpha;\n
}\n
);

        GPUClampingVertexLib = "GPUClamping.vert.lib.glsl";
        _sources[GPUClampingVertexLib] = OE_MULTILINE(// note: this is an include file\n
\n
// depth texture captures by the clamping technique\n
uniform sampler2D oe_clamp_depthTex;\n
\n
// matrix transforming from view space to depth-texture clip space\n
uniform mat4 oe_clamp_cameraView2depthClip;\n
\n
// matrix transform from depth-tecture clip space to view space\n
uniform mat4 oe_clamp_depthClip2cameraView;\n
\n
// Given a vertex in view space, clamp it to the "ground" as represented\n
// by an orthographic depth texture. Return the clamped vertex in view space,\n
// along with the associated depth value.\n
void oe_getClampedViewVertex(in vec4 vertView, out vec4 out_clampedVertView, out float out_depth)\n
{\n
    // transform the vertex into the depth texture's clip coordinates.\n
    vec4 vertDepthClip = oe_clamp_cameraView2depthClip * vertView;\n
\n
    // sample the depth map\n
    out_depth = texture2DProj( oe_clamp_depthTex, vertDepthClip ).r;\n
\n
    // now transform into depth-view space so we can apply the height-above-ground:\n
    vec4 clampedVertDepthClip = vec4(vertDepthClip.x, vertDepthClip.y, out_depth, 1.0);\n
\n
    // convert back into view space.\n
    out_clampedVertView = oe_clamp_depthClip2cameraView * clampedVertDepthClip;\n
}\n
\n
// Returns a vector indiciating the "down" direction.\n
void oe_getClampingUpVector(out vec3 up)\n
{\n
    up = normalize(mat3(oe_clamp_depthClip2cameraView) * vec3(0,0,-1));\n
}\n
\n
);


        // DrawInstanced
        InstancingVertex = "Instancing.vert.glsl";
        _sources[InstancingVertex] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
$__HASHTAG__extension GL_EXT_gpu_shader4 : enable\n
$__HASHTAG__extension GL_ARB_draw_instanced: enable\n
\n
$__HASHTAG__pragma vp_entryPoint oe_di_setInstancePosition\n
$__HASHTAG__pragma vp_location   vertex_model\n
$__HASHTAG__pragma vp_order      0.0\n
\n
uniform samplerBuffer oe_di_postex_TBO;\n
uniform int			  oe_di_postex_TBO_size;\n
\n
// Stage-global containing object ID\n
uint oe_index_objectid;\n
\n
void oe_di_setInstancePosition(inout vec4 VertexMODEL)\n
{ \n
    int index = 4 * gl_InstanceID;\n
\n
    vec4 m0 = texelFetch(oe_di_postex_TBO, index);\n
    vec4 m1 = texelFetch(oe_di_postex_TBO, index+1); \n
    vec4 m2 = texelFetch(oe_di_postex_TBO, index+2); \n
    vec4 m3 = texelFetch(oe_di_postex_TBO, index+3);\n
\n
    // decode the ObjectID from the last column:\n
    \n
    oe_index_objectid = uint(m3[0]) + (uint(m3[1]) << 8u) + (uint(m3[2]) << 16u) + (uint(m3[3]) << 24u);\n
    \n
    // rebuild positioning matrix and transform the vert. (Note, the matrix is actually\n
    // transposed so we have to reverse the multiplication order.)\n
    VertexMODEL = VertexMODEL * mat4(m0, m1, m2, vec4(0,0,0,1));\n
}\n
\n
);
    }
};
